# Test if we have any sort of consistency
# This simulates a larger tree and performs a topology search

import os

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
import numpy as np

Import('env')
localenv = env.Clone()

# Set up state
base = {'nreps': localenv['NREPS'],
        'output_name': localenv['OUTPUT_NAME']}

nest = SConsWrap(Nest(base_dict=base), '_'+localenv['OUTPUT_NAME'], alias_environment=localenv)

TARGET_LAMBDA_DICT = {
    "sorted": [
         [0.3,0.25,0.2,0.15,0.1,0.05],
	 [0.45,0.37,0.29,0.21,0.13,0.05]],
    "random": [
         [0.25,0.1,0.2,0.05,0.3,0.15],
	 [0.37,0.13,0.29,0.05,0.45,0.21]],
}

nest.add(
    'seed',
    range(401,405),
)

nest.add(
    'lambda_seq',
    [
	'sorted',
	'random',
    ])

nest.add(
    'lambda_scale',
    range(len(TARGET_LAMBDA_DICT["sorted"])),
    label_func=lambda c: "lam_scale%d" % c,
)

DOUBLE_CUTS = [1, 0.3]
nest.add(
    'double_cut',
    lambda c: DOUBLE_CUTS if c["lambda_scale"] == 0 else DOUBLE_CUTS[:1],
    label_func=lambda c: "double%d" % int(c * 10),
)

TRIM_ZERO_PROBS = [[0.1,0.1], [0.4,0.4]]
nest.add(
    'trim_zero_probs',
    lambda c: TRIM_ZERO_PROBS if c["lambda_scale"] == 0 and c["double_cut"] == DOUBLE_CUTS[0] else TRIM_ZERO_PROBS[:1],
    label_func=lambda c: "trim_zero_pr%d_%d" % (int(c[0] * 10), int(c[1] * 10)),
)

TRIM_POISSONS = [(3,3), (8,8)]
nest.add(
    'trim_poissons',
    lambda c: TRIM_POISSONS if c["lambda_scale"] == 0 and c["double_cut"] == DOUBLE_CUTS[0] and c["trim_zero_probs"] == TRIM_ZERO_PROBS[0] else TRIM_POISSONS[:1],
    label_func=lambda c: "trim_poiss%d_%d" % c,
)

nest.add(
    'trim_long_probs',
    [[0.01,0.01]],
    label_func=lambda c: "trim_long_pr%d_%d" % (int(c[0] * 10), int(c[1] * 10)),
)

INSERT_ZERO_PROBS = [0.05, 0.4]
nest.add(
    'insert_zero_prob',
    lambda c: INSERT_ZERO_PROBS if c["lambda_scale"] == 0 and c["double_cut"] == DOUBLE_CUTS[0] and c["trim_zero_probs"] == TRIM_ZERO_PROBS[0] and c["trim_poissons"] == TRIM_POISSONS[0] else INSERT_ZERO_PROBS[:1],
    label_func=lambda c: "insert_zero_pr%d" % int(c * 10),
)

INSERT_POISSONS = [1,4]
nest.add(
    'insert_poisson',
    lambda c: INSERT_POISSONS if c["lambda_scale"] == 0 and c["double_cut"] == DOUBLE_CUTS[0] and c["trim_zero_probs"] == TRIM_ZERO_PROBS[0] and c["trim_poissons"] == TRIM_POISSONS[0] and c["insert_zero_prob"] == INSERT_ZERO_PROBS[0] else INSERT_POISSONS[:1],
    label_func=lambda c: "insert_poiss%d" % c,
)

@nest.add_target_with_env(localenv)
def generate(env, outdir, c):
    targ_lambdas = ",".join(
	map(str, TARGET_LAMBDA_DICT[c['lambda_seq']][c['lambda_scale']]))

    sampling_rate = 0.4
    min_uniq_alleles = 10
    max_uniq_alleles = 30
    tree_time = 1
    birth_flag = '--birth-lambda 4'

    cmd = [
        'python boto_run.py',
	'2 2000',
	'generate_data.py',
	'--sampling-rate',
        sampling_rate,
        '--model-seed',
        400,
        '--data-seed',
        c['seed'],
        '--out-obs-file ${TARGETS[0]}',
        '--out-model-file ${TARGETS[1]}',
        '--log-file ${TARGETS[2]}',
        '--time',
        tree_time,
        birth_flag,
        '--num-barcodes',
        80,
        '--min-uniq-alleles',
        min_uniq_alleles,
        '--max-uniq-alleles',
        max_uniq_alleles,
        '--max-abundance 10',
        '--double-cut-weight',
        c['double_cut'],
        '--target-lambdas',
        targ_lambdas,
        '--trim-zero-probs',
        ' '.join(map(str, c['trim_zero_probs'])),
        '--trim-poissons',
        ' '.join(map(str, c['trim_poissons'])),
        '--trim-long-probs',
        ' '.join(map(str, c['trim_long_probs'])),
        '--insert-zero-prob',
        c['insert_zero_prob'],
        '--insert-poisson',
        c['insert_poisson'],
        '--perturb-target-lambdas-variance 0',
    ]
    # Just to make sure we dont rerun this command
    cmd = []
    return env.Command(
        [
            join(outdir, 'obs_data.pkl'),
            join(outdir, 'true_model.pkl'),
            join(outdir, 'log.txt')],
        [],
        ' '.join(map(str, cmd)))

nest.add(
    'num_barcodes',
    [5, 10, 20, 40],
    label_func=lambda c: "num_barcodes%d" % c,
)

@nest.add_target_with_env(localenv)
def restrict_observed_alleles(env, outdir, c):
    cmd = [
        'python boto_run.py',
	'2 2000',
        'restrict_observed_barcodes.py',
        '--obs-file ${SOURCES[0]}',
        '--model-file ${SOURCES[1]}',
        '--num-barcodes',
        c['num_barcodes'],
        '--out-obs-file ${TARGETS[0]}',
        '--out-collapsed-tree-file ${TARGETS[1]}',
        '--log-file ${TARGETS[2]}',
    ]
    cmd = []
    return env.Command(
        [
            join(outdir, 'obs_data.pkl'),
            join(outdir, 'collapsed_tree.pkl'),
            join(outdir, 'log_restrict.txt')],
        c['generate'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def run_topology(env, outdir, c):
    cmd = [
        'python boto_run.py',
	'2 6000',
        'get_parsimony_topologies.py',
        '--obs-file ${SOURCES[0]}',
        '--out-template-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}',
        '--max-random',
        0,
        '--max-random-multifurc',
        10,
        '--num-jumbles 1'
    ]
    cmd = []
    return env.Command(
        [
            join(outdir, 'parsimony_tree0.pkl'),
            join(outdir, 'log_parsimony.txt')],
        [
            c['restrict_observed_alleles'][0]],
        ' '.join(map(str, cmd)))

nest.add(
    'sum_states',
    [2000],
    label_func=lambda c: "sum_states%d" % c,
)

@nest.add_target_with_env(localenv)
def run_MLE(env, outdir, c):
    #penalty_params = ",".join(map(str, np.power(10, np.arange(0.5, -3.0, step=-1)).tolist()))
    penalty_params = "0.01"
    cmd = [
        'python boto_run.py',
	'18 25000',
	'tune_topology.py',
        '--obs-file ${SOURCES[0]}',
        '--topology-file ${SOURCES[1]}',
        '--true-model-file ${SOURCES[2]}',
        '--true-collapsed-tree-file ${SOURCES[3]}',
        '--out-model-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}',
        '--seed',
	c['seed'] + 100,
        '--log-barr 0.0000001',
        '--target-lam-pens',
	penalty_params,
        '--max-sum-states',
	c['sum_states'],
        '--max-extra-steps 2',
        '--max-iters 10000',
        '--train-split 0.75',
        '--num-inits 3'
    ]
    return env.Command(
        [
            join(outdir, 'tune_fitted.pkl'),
            join(outdir, 'tune_fitted_log.txt')],
        [
            c['restrict_observed_alleles'][0],
            c['run_topology'][0],
            c['generate'][1],
            c['restrict_observed_alleles'][1]],
        ' '.join(map(str, cmd)))

# Run plot_simulation_topol_consist.py to get summary measures
