{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from read_seq_data import parse_reads_file_format7B\n",
    "from models import EventType\n",
    "\n",
    "from constants import BARCODE_V7, NUM_BARCODE_V7_TARGETS\n",
    "\n",
    "\"\"\"\n",
    "A descriptive analysis of data from the first fish.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START_BASE = 120\n",
    "BARCODE_SPACER_LEN = 27\n",
    "TARGET_LEN = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell_reads = parse_reads_file_format7B(\"../data/fish_7B_UMI_collapsed_reads.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "distributions of the number of (visible) events in each cell type\n",
    "\"\"\"\n",
    "df = pd.DataFrame([(x.organ, len(x.uniq_events)) for x in cell_reads.all_barcodes],\n",
    "                  columns=('cell type', 'number of events'))\n",
    "plt.figure(figsize=(20, 3))\n",
    "sns.boxplot(x='cell type', y='number of events', data=df, color='lightgrey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "distributions of the number of exhausted targets in each cell type\n",
    "\"\"\"\n",
    "df = pd.DataFrame([(x.organ, sum(len(y) != 0 for y in x.events)) for x in cell_reads.all_barcodes],\n",
    "                  columns=('cell type', 'number of exhausted targets'))\n",
    "plt.figure(figsize=(20, 3))\n",
    "sns.violinplot(x='cell type', y='number of exhausted targets', data=df, color='lightgrey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Really basic data characteristics\n",
    "\"\"\"\n",
    "num_cells = len(cell_reads.all_barcodes)\n",
    "print(\"# of cells:\", num_cells)\n",
    "print(\"# of unique barcodes (alleles):\", len(cell_reads.uniq_barcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Organ data distribution\n",
    "\"\"\"\n",
    "organ_barcode_dict = dict()\n",
    "for b in cell_reads.all_barcodes:\n",
    "    if b.organ not in organ_barcode_dict:\n",
    "        organ_barcode_dict[b.organ] = []\n",
    "    organ_barcode_dict[b.organ].append(b)\n",
    "    \n",
    "for organ, barcodes in organ_barcode_dict.items():\n",
    "    bcode_strs = [\".\".join([str(evt) for evt in b.uniq_events]) for b in barcodes]\n",
    "    uniq_bcodes = set(bcode_strs)\n",
    "    num_organ_cells = len(barcodes)\n",
    "    print(\"# of %s cells: %d (%f%%)\" % (organ, num_organ_cells, (100 * num_organ_cells)/num_cells))\n",
    "    print(\"  # of unique barcodes:\", len(uniq_bcodes))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process unique insertions\n",
    "uniq_inserts = set()\n",
    "uniq_insert_strs = set()\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    for evt in b.uniq_events:\n",
    "        if evt.event_type == EventType.INSERT:\n",
    "            if evt.get_str_id() in uniq_insert_strs:\n",
    "                continue\n",
    "            else:\n",
    "                uniq_insert_strs.add(evt.get_str_id())\n",
    "                uniq_inserts.add(evt)\n",
    "\n",
    "# Process insertions with target idx\n",
    "all_insert_target_pos = []\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    all_target_evts = b.events\n",
    "    for target_i, target_evts in enumerate(all_target_evts):\n",
    "        for evt in target_evts:\n",
    "            if evt.event_type == EventType.INSERT:\n",
    "                all_insert_target_pos.append((target_i, evt))\n",
    "all_insert_target_pos = np.array(all_insert_target_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Interpretation: There aren't that many insertion locations possible\n",
    "\"\"\"\n",
    "num_insert_evt = np.sum([str_id.startswith(\"EventType.INSERT\") for str_id in cell_reads.event_str_ids])\n",
    "print(\"# unique insertion events:\", num_insert_evt)\n",
    "insert_pos = [ins.start_pos for ins in uniq_inserts]\n",
    "num_uniq_insert_start = np.unique(insert_pos).size\n",
    "print(\"# unique insertion positions:\", num_uniq_insert_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A summary table of the length of unique insertion events\n",
    "\n",
    "Interpretation: There is actually a wide range of insertion lengths (up to 48 bp!).\n",
    "Most insertions are short. However some insertion lengths seem to be more favorable.\n",
    "Even though we only look at unique insertions, there are a large number of\n",
    "unique insertions that are all length 12, 15, 20, and 23.\n",
    "\"\"\"\n",
    "insert_len = [ins.event_len for ins in uniq_inserts]\n",
    "Counter(insert_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Where are things inserted for each target, what is the usual position, what is the usual length?\n",
    "The numbers below are median (min, max)\n",
    "\n",
    "Interpretation: Looks like insertion location is not always at the cut site. It could be a little left\n",
    "of the cut site due to simultaneous deletions maybe?\n",
    "\"\"\"\n",
    "insert_target_summary = [\n",
    "    {'count': 0, 'locations': [], 'lengths': [], 'uniq_strs': set()} for i in range(NUM_BARCODE_V7_TARGETS)\n",
    "]\n",
    "for target_i, evt in all_insert_target_pos:\n",
    "    if evt.get_str_id() in insert_target_summary[target_i]['uniq_strs']:\n",
    "        continue\n",
    "    else:\n",
    "        insert_target_summary[target_i]['uniq_strs'].add(evt.get_str_id())\n",
    "        insert_target_summary[target_i][\"count\"] += 1\n",
    "        insert_target_summary[target_i][\"locations\"].append(evt.start_pos)\n",
    "        insert_target_summary[target_i][\"lengths\"].append(evt.event_len)\n",
    "\n",
    "for target_i, target_dict in enumerate(insert_target_summary):\n",
    "    print(\"Target\", target_i)\n",
    "    print(\"  Count:\", target_dict['count'])\n",
    "    locs = target_dict['locations']\n",
    "    print(\"  Location:\", np.median(locs), \"(\", np.min(locs), \",\", np.max(locs), \")\")\n",
    "    lens = target_dict['lengths']\n",
    "    print(\"  Lengths:\", np.median(lens), \"(\", np.min(lens), \",\", np.max(lens), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot: histogram of insertion positions\n",
    "\n",
    "Interpretation: Most insertion positions are centered around the cutting locations.\n",
    "The cut locations are almost equally spaced apart, with some jitter. (This is just a more visual\n",
    "plot of the list above.)\n",
    "\"\"\"\n",
    "plt.hist(insert_pos, bins=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Understanding simultaneous deletions and insertions (those that occur in the same position)\n",
    "\n",
    "Interpretation: There are 10/59 insertion events that overlap with a deletion event on the same barcode.\n",
    "My guess is that the two happened at the same time.\n",
    "However I'm a bit surprised that we don't have simultaneous deletion and insertion more often.\n",
    "\"\"\"\n",
    "simult_del_ins = set()\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    for target_evts in b.events:\n",
    "        insert_evts = [evt.event_type == EventType.INSERT for evt in target_evts]\n",
    "        delete_evts = [evt.event_type == EventType.DELETE for evt in target_evts]\n",
    "        insert_offset_posns = [evt.start_pos + 1 for evt in target_evts if evt.event_type == EventType.INSERT]\n",
    "        delete_posns = [evt.start_pos for evt in target_evts if evt.event_type == EventType.DELETE]\n",
    "        num_intersects = (set(insert_offset_posns)).intersection(set(delete_posns))\n",
    "        if len(num_intersects) == 1:\n",
    "            del_idx = delete_evts.index(True)\n",
    "            ins_idx = insert_evts.index(True)\n",
    "            simult_del_ins.add(target_evts[ins_idx].get_str_id() + \"--\" + target_evts[del_idx].get_str_id())\n",
    "print(\"# simultaneous delete and insert:\", len(simult_del_ins))\n",
    "for del_in in simult_del_ins:\n",
    "    print(del_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Understanding complex events involving insertions.\n",
    "Complex events mean there are more than two events in a single target.\n",
    "\n",
    "Interpretation: There are actually plenty of insertion events without a deletion event.\n",
    "There are also insertion events with non-overlapping deletion events. I'm not sure why these occur --\n",
    "is it possible that when we repair the barcode, we actually have a double-strand break in some place and\n",
    "we patch in a couple of the same bases AND insert some new bases?\n",
    "There are also double insertions in the same target.\n",
    "If there are multiple events in the same target, usually the events occur close to each other.\n",
    "It seems like some of these events actually occurred simultaneously, even though we're processing as separate\n",
    "events right now.\n",
    "\"\"\"\n",
    "many_inserts_same_target = set()\n",
    "inserts_no_dels_same_target = set()\n",
    "inserts_no_dels_same_target_start = []\n",
    "del_ins_no_simul_same_target = set()\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    for target_evts in b.events:\n",
    "        insert_evts = [evt.event_type == EventType.INSERT for evt in target_evts]\n",
    "        delete_evts = [evt.event_type == EventType.DELETE for evt in target_evts]\n",
    "        target_evt_str = \"--\".join([evt.get_str_id() for evt in target_evts])\n",
    "        if any(insert_evts) and not any(delete_evts):\n",
    "            inserts_no_dels_same_target.add(target_evt_str)\n",
    "            inserts_no_dels_same_target_start.append(target_evts[0].start_pos)\n",
    "        if sum(insert_evts) >= 2:\n",
    "            many_inserts_same_target.add(target_evt_str)\n",
    "        if any(insert_evts):\n",
    "            insert_offset_posns = [evt.start_pos + 1 for evt in target_evts if evt.event_type == EventType.INSERT]\n",
    "            delete_posns = [evt.start_pos for evt in target_evts if evt.event_type == EventType.DELETE]\n",
    "            num_intersects = (set(insert_offset_posns)).intersection(set(delete_posns))\n",
    "            if len(num_intersects) == 0:\n",
    "                target_evt_str = \"--\".join([evt.get_str_id() for evt in target_evts])\n",
    "                del_ins_no_simul_same_target.add(target_evt_str)\n",
    "\n",
    "print(\"# insert in a target without any deletions:\", len(inserts_no_dels_same_target))\n",
    "print(\"# 2+-insertions in a target:\", len(many_inserts_same_target))\n",
    "print(\"# inserts in a target without overlapping deletions:\", len(del_ins_no_simul_same_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What are the insertion positions if there are no deletions for that target?\n",
    "\n",
    "Interpretation: How can we have 46 different insertion positions when we can only introduce double\n",
    "stranded breaks at 10 positions in the barcode?\n",
    "\"\"\"\n",
    "plt.hist(inserts_no_dels_same_target_start, bins=30)\n",
    "print(\"# of unique insertion start pos:\", len(set(inserts_no_dels_same_target_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process unique deletions\n",
    "uniq_deletes = set()\n",
    "uniq_delete_strs = set()\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    for evt in b.uniq_events:\n",
    "        if evt.event_type == EventType.DELETE:\n",
    "            if evt.get_str_id() in uniq_delete_strs:\n",
    "                continue\n",
    "            else:\n",
    "                uniq_delete_strs.add(evt.get_str_id())\n",
    "                uniq_deletes.add(evt)\n",
    "\n",
    "# Process deletions with target idx\n",
    "all_delete_target_pos = []\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    all_target_evts = b.events\n",
    "    for target_i, target_evts in enumerate(all_target_evts):\n",
    "        for evt in target_evts:\n",
    "            if evt.event_type == EventType.DELETE:\n",
    "                all_delete_target_pos.append((target_i, evt))\n",
    "all_delete_target_pos = np.array(all_delete_target_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Counting deletion events and positions\n",
    "\n",
    "Interpretation: There are quite a lot of deletion positions possible. The total barcode is only 270 long.\n",
    "We are starting deletes from almost every position.\n",
    "\"\"\"\n",
    "num_delete_evt = np.sum([str_id.startswith(\"EventType.DELETE\") for str_id in cell_reads.event_str_ids])\n",
    "print(\"# unique delete events:\", num_delete_evt)\n",
    "delete_pos = [deletion.start_pos for deletion in uniq_deletes]\n",
    "num_uniq_delete_start = np.unique(delete_pos).size\n",
    "print(\"# unique deletion start positions:\", num_uniq_delete_start)\n",
    "delete_end_pos = [deletion.start_pos + deletion.event_len - 1 for deletion in uniq_deletes]\n",
    "num_uniq_delete_end = np.unique(delete_end_pos).size\n",
    "print(\"# unique deletion end positions:\", num_uniq_delete_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Histogram of the lengths of deletions\n",
    "\n",
    "Interpretation: Wide range of deletion lengths possible, though more often we delete short lengths.\n",
    "We even have deletions of 222 bp.\n",
    "\"\"\"\n",
    "# A summary table of the length of unique deletion events\n",
    "del_len = [ins.event_len for ins in uniq_deletes]\n",
    "plt.hist(del_len, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot: histogram of deletion start locations\n",
    "\n",
    "Picture: deletion start locations for each unique deletion event.\n",
    "You can spot 10 peaks, but it's a bit difficult. Deleions can start anywhere!\n",
    "\"\"\"\n",
    "plt.hist(delete_pos, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot: histogram of deletion end locations\n",
    "\n",
    "You can spot 10 peaks, but it's a bit difficult. Deletions can end anywhere!\n",
    "\"\"\"\n",
    "plt.hist(delete_end_pos, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Where are things deleted for each target, what is the usual position, what is the usual length?\n",
    "The numbers below are median (min, max)\n",
    "\n",
    "Interpretation: The median position for the deletion for each target is pretty evenly spaced.\n",
    "Median deletion length is actually quite high!\n",
    "\"\"\"\n",
    "del_target_summary = [\n",
    "    {'count': 0, 'locations': [], 'lengths': [], 'uniq_strs': set()}\n",
    "    for i in range(NUM_BARCODE_V7_TARGETS)\n",
    "]\n",
    "for target_i, evt in all_delete_target_pos:\n",
    "    is_target_i_start = evt.start_pos >= START_BASE + BARCODE_SPACER_LEN * target_i\n",
    "    is_target_i_end = evt.start_pos <= START_BASE + BARCODE_SPACER_LEN * (target_i + 1)\n",
    "    if is_target_i_start and is_target_i_end:\n",
    "        if evt.get_str_id() in del_target_summary[target_i]['uniq_strs']:\n",
    "            continue\n",
    "        else:\n",
    "            del_target_summary[target_i]['uniq_strs'].add(evt.get_str_id())\n",
    "            del_target_summary[target_i][\"count\"] += 1\n",
    "            del_target_summary[target_i][\"locations\"].append(evt.start_pos)\n",
    "            del_target_summary[target_i][\"lengths\"].append(evt.event_len)\n",
    "\n",
    "for target_i, target_dict in enumerate(del_target_summary):\n",
    "    print(\"Target\", target_i)\n",
    "    print(\"  Count:\", target_dict['count'])\n",
    "    locs = target_dict['locations']\n",
    "    print(\"  Location:\", np.median(locs), \"(\", np.min(locs), \",\", np.max(locs), \")\")\n",
    "    lens = target_dict['lengths']\n",
    "    print(\"  Lengths:\", np.median(lens), \"(\", np.min(lens), \",\", np.max(lens), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot: deletion length histogram for deletion events that start at this target.\n",
    "\n",
    "Interpretation: The deletion length profiles vary across the targets.\n",
    "The deletion lengths can vary widely, some going up to 200+ bp.\n",
    "Shorter deletions are preferred.\n",
    "\"\"\"\n",
    "plt.figure(figsize=(8,14))\n",
    "for target_i, target_dict in enumerate(del_target_summary):\n",
    "    print(\"Target\", target_i)\n",
    "    plt.subplot(NUM_BARCODE_V7_TARGETS, 1, target_i + 1, xlim = [0, 250])\n",
    "    plt.hist(target_dict['lengths'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How often do intertarget deletions occur?\n",
    "e.g. do targets 0 and 9 often get cut together?\n",
    "\n",
    "Interpretation: most deletions are in the same target. The next most common deletions occur across two targets.\n",
    "There are very few very long inter-target deletions.\n",
    "\"\"\"\n",
    "uniq_deletion_strs = set()\n",
    "intertarget_pairs = np.zeros((NUM_BARCODE_V7_TARGETS, NUM_BARCODE_V7_TARGETS))\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    deletions = dict()\n",
    "    for target_idx, target_evts in enumerate(b.events):\n",
    "        for evt in target_evts:\n",
    "            if evt.event_type == EventType.DELETE:\n",
    "                evt_id = evt.get_str_id()\n",
    "                if evt_id in deletions:\n",
    "                    deletions[evt_id].append(target_idx)\n",
    "                else:\n",
    "                    deletions[evt_id] = [target_idx]\n",
    "    for del_evt, del_targets in deletions.items():\n",
    "        if del_evt in uniq_deletion_strs:\n",
    "            continue\n",
    "        else:\n",
    "            uniq_deletion_strs.add(del_evt)\n",
    "            intertarget_pairs[min(del_targets), max(del_targets)] += 1\n",
    "plt.imshow(intertarget_pairs, cmap='hot')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Understanding double deletions in the same target\n",
    "\n",
    "Interpretation: There are actually some double deletions within the same target.\n",
    "I think it was because a longer deletion occurred but some of the same nucleotides\n",
    "were patched back in so that it may be mis-interpretted as two events instead of\n",
    "a single one.\n",
    "\"\"\"\n",
    "many_dels_same_target = set()\n",
    "many_short_dels_same_target = set()\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    for target_evts in b.events:\n",
    "        event_lens = [evt.event_len for evt in target_evts if evt.event_type == EventType.DELETE]\n",
    "        if len(event_lens) >= 2:\n",
    "            target_evt_str = \"--\".join([evt.get_str_id() for evt in target_evts])\n",
    "            many_dels_same_target.add(target_evt_str)\n",
    "            if np.all(np.array(event_lens) < TARGET_LEN/2):\n",
    "                many_short_dels_same_target.add(target_evt_str)\n",
    "\n",
    "print(\"# 2+-deletions in a target:\", len(many_dels_same_target))\n",
    "print(\"# 2+-short-deletions (11 bp or less) in a target:\", len(many_short_dels_same_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Average number of targets disturbed for each barcode\n",
    "\n",
    "Interpretation: Most barcodes have most targets modified by the time we sequence.\n",
    "This is like how the paper mentioned that we have saturated the barcodes.\n",
    "\"\"\"\n",
    "all_num_disturbed = []\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    num_disturbed = sum([len(target_evts) >= 1 for target_evts in b.events])\n",
    "    all_num_disturbed.append(num_disturbed)\n",
    "Counter(all_num_disturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Number of insert-delete pairs where the deletion event is the same but the insertion event is different\n",
    "\n",
    "Interpretation:\n",
    "(1) If a single barcode contains the same deletion event but different insertion events,\n",
    "this likely occurred from separate deletion events. However, one might be tempted to group these\n",
    "events together. These 8 insert-delete pairs were probably incorrectly interpreted by parsimony.\n",
    "\n",
    "(2) It is difficult to distinguish when two barcodes have the same deletion event due to cell\n",
    "replication vs. the deletion events happened on separate cells and just happened to delete the same\n",
    "sequence. However the barcodes below suggest that it is possible for the same deletion events to\n",
    "happen instantaneously from separate cells. We see that among all the insertion-deletion pairs\n",
    "(there are 78 of them), 18 of them involve the same deletion event. That's nearly 25%!\n",
    "\"\"\"\n",
    "del_ins_same_target = set()\n",
    "for b in cell_reads.uniq_barcodes:\n",
    "    for target_evts in b.events:\n",
    "        insert_evts = [evt.event_type == EventType.INSERT for evt in target_evts]\n",
    "        delete_evts = [evt.event_type == EventType.DELETE for evt in target_evts]\n",
    "        target_evt_str = \"-\".join(\n",
    "            [\n",
    "                \"%d+%d\" % (evt.start_pos, evt.event_len)\n",
    "                 for evt in target_evts if evt.event_type == EventType.DELETE\n",
    "            ]\n",
    "        )\n",
    "        target_other_str = \"-\".join([evt.get_str_id() for evt in target_evts])\n",
    "        if any(insert_evts) and any(delete_evts):\n",
    "            del_ins_same_target.add(target_evt_str + \"===\" + target_other_str)\n",
    "\n",
    "num_del_ins_same_target = len(del_ins_same_target)\n",
    "num_sep_but_same = 0\n",
    "del_ins_same_target = sorted(del_ins_same_target)\n",
    "prev_ev_list = []\n",
    "prev_list = []\n",
    "for e in del_ins_same_target:\n",
    "    check_e = e.split(\"===\")[0]\n",
    "    prefix = sorted(check_e.split(\"-\"))\n",
    "    if prefix == prev_ev_list:\n",
    "        prev_list.append(e)\n",
    "    else:\n",
    "        if len(prev_list) >= 2:\n",
    "            num_sep_but_same += len(prev_list)\n",
    "            print(\"===========\")\n",
    "            for l in prev_list:\n",
    "                print(l.split(\"===\")[1])\n",
    "        prev_ev_list = prefix\n",
    "        prev_list = [e]\n",
    "\n",
    "print(\"\\n# insertion and deletion pairs:\", num_del_ins_same_target)\n",
    "print(\"# insertion and deletion pairs with same deletion, diff insertion:\", num_sep_but_same)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
