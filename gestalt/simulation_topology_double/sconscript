# Understand what toggles are important for topology recovery
# How big should hte double weight be?

import os
import random

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
import numpy as np

Import('env')
localenv = env.Clone()

# Set up state
base = {'nreps': localenv['NREPS'],
        'output_name': localenv['OUTPUT_NAME']}

nest = SConsWrap(Nest(base_dict=base), '_'+localenv['OUTPUT_NAME'], alias_environment=localenv)

NUM_TARGS = 6
LAM_MAG = 0.35
LAMBDA_SEQUENCE = np.ones(NUM_TARGS) * LAM_MAG
TOT_HAZ = LAM_MAG * LAM_MAG * NUM_TARGS * (NUM_TARGS - 1) /2 + LAM_MAG * NUM_TARGS

nest.add(
    'model_seed',
    [500],
    label_func=lambda c: 'model_seed%d' % c,
)

nest.add(
    'seed',
    range(0, 5),
)
DOUBLE_CUT_WEIGHTS = [0.2, 0.8, 3.2]
nest.add(
    'double_cut',
    DOUBLE_CUT_WEIGHTS,
    label_func=lambda c: 'double_cut%d' % int(c * 10))

@nest.add_target_with_env(localenv)
def generate(env, outdir, c):
    lambda_mag = LAM_MAG
    tot_haz = lambda_mag * lambda_mag * NUM_TARGS * (NUM_TARGS - 1) /2 * c['double_cut'] + lambda_mag * NUM_TARGS
    while np.abs(tot_haz - TOT_HAZ) > 0.1:
        if tot_haz > TOT_HAZ:
            lambda_mag -= 0.01
        else:
            lambda_mag += 0.01
        tot_haz = lambda_mag * lambda_mag * NUM_TARGS * (NUM_TARGS - 1) /2 * c['double_cut'] + lambda_mag * NUM_TARGS
    print(lambda_mag, tot_haz)
    lambda_seq = [lambda_mag] * NUM_TARGS
    targ_lambdas = ",".join(map(str, lambda_seq))

    cmd = [
        'python boto_run.py 2 2000 generate_data.py',
	#'python generate_data.py',
	'--sampling-rate 0.4',
        '--model-seed',
        c['model_seed'],
        '--data-seed',
        c['seed'],
        '--out-obs-file ${TARGETS[0]}',
        '--out-model-file ${TARGETS[1]}',
        '--log-file ${TARGETS[2]}',
        '--time 1',
        '--birth-lambda 6',
        '--num-barcodes',
        30,
        '--min-uniq-alleles 50',
        '--max-uniq-alleles 70',
        '--max-abundance 10',
        '--double-cut-weight',
        c['double_cut'],
        '--target-lambdas',
        targ_lambdas,
        '--trim-zero-probs 0.1 0.1',
        '--trim-poissons 4 4',
        '--trim-long-probs 0.02 0.02',
        '--insert-zero-prob 0.1',
        '--insert-poisson 1',
        '--perturb-target-lambdas-variance 0',
    ]
    return env.Command(
        [
            join(outdir, 'obs_data.pkl'),
            join(outdir, 'true_model.pkl'),
            join(outdir, 'log.txt')],
        [],
        ' '.join(map(str, cmd)))

nest.add(
    'num_barcodes',
    [1, 9],
    label_func=lambda c: "num_barcodes%d" % c,
)

@nest.add_target_with_env(localenv)
def restrict_observed_alleles(env, outdir, c):
    cmd = [
        #'python boto_run.py 2 2000 restrict_observed_barcodes.py',
        'python3 restrict_observed_barcodes.py',
        '--obs-file ${SOURCES[0]}',
        '--model-file ${SOURCES[1]}',
        '--num-barcodes',
        c['num_barcodes'],
        '--out-obs-file ${TARGETS[0]}',
        '--out-collapsed-tree-file ${TARGETS[1]}',
        '--log-file ${TARGETS[2]}',
    ]
    cmd = []
    return env.Command(
        [
            join(outdir, 'obs_data.pkl'),
            join(outdir, 'collapsed_tree.pkl'),
            join(outdir, 'log_restrict.txt')],
        c['generate'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def run_topology(env, outdir, c):
    cmd = [
        #'python boto_run.py 2 6000 get_parsimony_topologies.py',
        'python3 get_parsimony_topologies.py',
        '--obs-file ${SOURCES[0]}',
        '--out-template-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}',
        '--max-random',
        0,
        '--max-random-multifurc',
        4,
        '--num-jumbles 1'
    ]
    cmd  = []
    return env.Command(
        [
            join(outdir, 'parsimony_tree0.pkl'),
            join(outdir, 'log_parsimony.txt')],
        [
            c['restrict_observed_alleles'][0]],
        ' '.join(map(str, cmd)))

nest.add(
    'sum_states',
    [2000],
    label_func=lambda c: "sum_states%d" % c,
)

@nest.add_target_with_env(localenv)
def run_MLE(env, outdir, c):
    #penalty_params = ",".join(map(str, np.power(10, np.arange(0.5, -3.0, step=-1)).tolist()))
    penalty_params = "0.01" if c['num_barcodes'] > 3 else "0.1"
    cmd = [
        'python boto_run.py 18 25000 tune_topology.py',
        #'srun -p matsen_e,campus',
        #'--cpus-per-task 4' if c['num_barcodes'] < 3 else '--cpus-per-task 6',
	#'python tune_topology.py',
        '--obs-file ${SOURCES[0]}',
        '--topology-file ${SOURCES[1]}',
        '--true-model-file ${SOURCES[2]}',
        '--true-collapsed-tree-file ${SOURCES[3]}',
        '--out-model-file ${TARGETS[0]}',
        '--log-file ${TARGETS[1]}',
        '--seed',
	c['seed'] + 100,
        '--log-barr 0.0000001',
        '--target-lam-pens',
	penalty_params,
        '--max-sum-states',
	c['sum_states'],
        '--max-extra-steps 2',
        '--max-iters 10000',
        '--train-split 0.75',
        '--num-inits 3',
        #'--submit-srun' if c['num_barcodes'] < 3 else ''
    ]
    return env.Command(
        [
            join(outdir, 'tune_fitted.pkl'),
            join(outdir, 'tune_fitted_log.txt')],
        [
            c['restrict_observed_alleles'][0],
            c['run_topology'][0],
            c['generate'][1],
            c['restrict_observed_alleles'][1]],
        ' '.join(map(str, cmd)))

